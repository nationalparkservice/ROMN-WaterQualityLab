{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "HJ_nLmy4q_fn"
   },
   "outputs": [],
   "source": [
    "# Created by Balakrishna Vagvala and Sherrill Kirk\n",
    "# This code depends upon the packages and libraries listed in the next cell\n",
    "# Date of creation: 12/1/2020\n",
    "# Script purpose: this script processes the OSU CCAL Lab delivered data, compares with expected fields file and make ready to be uploaded to database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zfqegHbBgVt_",
    "outputId": "bff686fa-f7d8-49d8-90ae-0b21c330ea3d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\ROMN\\working\\Misc\\4People\\4Bala\\WaterQualityProcessing\\CCAL\\2020\\Preproccessed2\n"
     ]
    }
   ],
   "source": [
    "#importing pandas for data operations, numpy for numerical operations. time is used to have present time.\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "#sequence matcher is used to compare strings and openpyxl is used to write workbooks.\n",
    "from difflib import SequenceMatcher\n",
    "from openpyxl import load_workbook\n",
    "from shutil import copyfile\n",
    "#cd to change current directory where output goes. this has to be manually entered\n",
    "%cd D:\\ROMN\\working\\Misc\\4People\\4Bala\\WaterQualityProcessing\\CCAL\\2020\\Preproccessed2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vhmE5T3u7VxB",
    "outputId": "52bd2f76-e443-4c41-c3d3-268ecd9f0dce"
   },
   "outputs": [],
   "source": [
    "# mounting google drive for google collab, not needed for native IDE's\n",
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "2KIaL9VM7xac"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GRKO_032620_changed_names.xlsx\n"
     ]
    }
   ],
   "source": [
    "#importing reading functions and declaring the location of our file.\n",
    "import os, glob\n",
    "#file to check crosswalks, i.e field names, this is an excel file's path\n",
    "crosswalk = r'D:\\ROMN\\working\\Misc\\4People\\4Bala\\WaterQualityProcessing\\CCAL\\OSU_CCAL_ExpectedFields_CrossWalk_20201214.xlsx'\n",
    "#toread crosswalk file\n",
    "crosswalk = pd.read_excel(crosswalk)\n",
    "#file to process , this is an excel file's path\n",
    "data = r'D:\\ROMN\\working\\Misc\\4People\\4Bala\\WaterQualityProcessing\\CCAL\\2020\\GRKO_032620_changed_names.xlsx'\n",
    "\n",
    "\n",
    "currentoutputpath= r'D:\\ROMN\\working\\Misc\\4People\\4Bala\\WaterQualityProcessing\\CCAL\\2020\\Preproccessed2'\n",
    "\n",
    "filename= os.path.basename(data)\n",
    "print(filename)\n",
    "\n",
    "firstline=[]\n",
    "firstline.append(\"File Being Processed is: \" + filename+ \"\\n \\n \\n#########\\n\\n\" )\n",
    "#toread the lab file, we mention sheet name of excel file in the second argument, here GRKO Data is our sheet name in excel file by lab\n",
    "# osudata = pd.read_excel(data, 'GRKO Data')\n",
    "#to specify sheet number instead of sheet name\n",
    "osudata = pd.read_excel(data, sheet_name = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "Gi5mSb519Ljm"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SampleName</th>\n",
       "      <th>Project Code</th>\n",
       "      <th>Lab Number</th>\n",
       "      <th>Site ID</th>\n",
       "      <th>Remark</th>\n",
       "      <th>Delivery Date</th>\n",
       "      <th>Alkalinity\\n(mg)</th>\n",
       "      <th>Date</th>\n",
       "      <th>DOC (mg C/L)</th>\n",
       "      <th>Date</th>\n",
       "      <th>...</th>\n",
       "      <th>SO4-S\\r\\n(mg S/L)</th>\n",
       "      <th>Date</th>\n",
       "      <th>NO3\\n(mg/L)</th>\n",
       "      <th>Date</th>\n",
       "      <th>Na\\n(mg/L)</th>\n",
       "      <th>Date</th>\n",
       "      <th>Duplicate NO3\\r\\n(mg/L)</th>\n",
       "      <th>Date</th>\n",
       "      <th>Cl (mg/L) Cl(mg/L)</th>\n",
       "      <th>pqrstuvwxyz</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GRKO101</td>\n",
       "      <td>GRKO</td>\n",
       "      <td>101</td>\n",
       "      <td>19NPS0000602</td>\n",
       "      <td>GRKO_S01 3/24/20 13:45</td>\n",
       "      <td>3/26/2020</td>\n",
       "      <td>134.90</td>\n",
       "      <td>4/28/2020</td>\n",
       "      <td>12.50</td>\n",
       "      <td>4/14/2020</td>\n",
       "      <td>...</td>\n",
       "      <td>34.91</td>\n",
       "      <td>5/13/2020</td>\n",
       "      <td>17.07</td>\n",
       "      <td>6/2/2020</td>\n",
       "      <td>0.81</td>\n",
       "      <td>4/29/2020</td>\n",
       "      <td>0.82</td>\n",
       "      <td>4/29/2020</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 44 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  SampleName Project Code Lab Number       Site ID                   Remark  \\\n",
       "1    GRKO101         GRKO        101  19NPS0000602   GRKO_S01 3/24/20 13:45   \n",
       "\n",
       "  Delivery Date Alkalinity\\n(mg)       Date DOC (mg C/L)       Date  ...  \\\n",
       "1     3/26/2020           134.90  4/28/2020        12.50  4/14/2020  ...   \n",
       "\n",
       "  SO4-S\\r\\n(mg S/L)       Date NO3\\n(mg/L)      Date Na\\n(mg/L)       Date  \\\n",
       "1             34.91  5/13/2020       17.07  6/2/2020       0.81  4/29/2020   \n",
       "\n",
       "  Duplicate NO3\\r\\n(mg/L)       Date Cl (mg/L) Cl(mg/L) pqrstuvwxyz  \n",
       "1                    0.82  4/29/2020                NaN         NaN  \n",
       "\n",
       "[1 rows x 44 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#here we process our data so that we have just the field names and field values in our dataframe\n",
    "firstline.append(\"File \" + filename+ \" is Processed \\n \\n \\n#########\\n\" )\n",
    "df = osudata\n",
    "df = df.iloc[2:]\n",
    "df = df.rename(columns=df.iloc[0])\n",
    "df.reset_index(inplace=True)\n",
    "df = df.iloc[1:,1:]\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "PyqVRPFIvHiQ"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SampleName</th>\n",
       "      <th>Project Code</th>\n",
       "      <th>Lab Number</th>\n",
       "      <th>Site ID</th>\n",
       "      <th>Remark</th>\n",
       "      <th>Delivery Date</th>\n",
       "      <th>Alkalinity (mg)</th>\n",
       "      <th>Date</th>\n",
       "      <th>DOC (mg C/L)</th>\n",
       "      <th>Date</th>\n",
       "      <th>...</th>\n",
       "      <th>SO4-S (mg S/L)</th>\n",
       "      <th>Date</th>\n",
       "      <th>NO3 (mg/L)</th>\n",
       "      <th>Date</th>\n",
       "      <th>Na (mg/L)</th>\n",
       "      <th>Date</th>\n",
       "      <th>Duplicate NO3 (mg/L)</th>\n",
       "      <th>Date</th>\n",
       "      <th>Cl (mg/L) Cl(mg/L)</th>\n",
       "      <th>pqrstuvwxyz</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GRKO101</td>\n",
       "      <td>GRKO</td>\n",
       "      <td>101</td>\n",
       "      <td>19NPS0000602</td>\n",
       "      <td>GRKO_S01 3/24/20 13:45</td>\n",
       "      <td>3/26/2020</td>\n",
       "      <td>134.90</td>\n",
       "      <td>4/28/2020</td>\n",
       "      <td>12.50</td>\n",
       "      <td>4/14/2020</td>\n",
       "      <td>...</td>\n",
       "      <td>34.91</td>\n",
       "      <td>5/13/2020</td>\n",
       "      <td>17.07</td>\n",
       "      <td>6/2/2020</td>\n",
       "      <td>0.81</td>\n",
       "      <td>4/29/2020</td>\n",
       "      <td>0.82</td>\n",
       "      <td>4/29/2020</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 44 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  SampleName Project Code Lab Number       Site ID                   Remark  \\\n",
       "1    GRKO101         GRKO        101  19NPS0000602   GRKO_S01 3/24/20 13:45   \n",
       "\n",
       "  Delivery Date Alkalinity (mg)       Date DOC (mg C/L)       Date  ...  \\\n",
       "1     3/26/2020          134.90  4/28/2020        12.50  4/14/2020  ...   \n",
       "\n",
       "  SO4-S (mg S/L)       Date NO3 (mg/L)      Date Na (mg/L)       Date  \\\n",
       "1          34.91  5/13/2020      17.07  6/2/2020      0.81  4/29/2020   \n",
       "\n",
       "  Duplicate NO3 (mg/L)       Date Cl (mg/L) Cl(mg/L) pqrstuvwxyz  \n",
       "1                 0.82  4/29/2020                NaN         NaN  \n",
       "\n",
       "[1 rows x 44 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# to remove \\n and \\r from lab delivareables, they are influencing our data and output, so we are removing them\n",
    "\n",
    "dfStrip = osudata.replace('\\n',' ', regex=True)\n",
    "\n",
    "dfStrip2 = dfStrip.replace('\\r','', regex=True)\n",
    "\n",
    "df = dfStrip2\n",
    "\n",
    "df = df.iloc[2:]\n",
    "\n",
    "df = df.rename(columns=df.iloc[0])\n",
    "\n",
    "df.reset_index(inplace=True)\n",
    "\n",
    "df = df.iloc[1:,1:]\n",
    "\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "osufields = list(df.columns)\n",
    "labfields = crosswalk['NativeDeliveryFIelds'].tolist()\n",
    "expectedfields = crosswalk['CrossWalkedFields'].tolist()\n",
    "timestr = time.strftime(\"_%y_%m_%d_%H_%M\")\n",
    "# this cell is to check for coloumns and export irregularities into warning list\n",
    "f= open(\"warning_list of \"+filename+\" at \"+timestr+\".txt\",\"w+\")\n",
    "matchingfields =[]\n",
    "morethanninety = []\n",
    "lessthanninety = []\n",
    "newfields=[]\n",
    "duplicatefields=[]\n",
    "missedfields = []\n",
    "p=''\n",
    "q=''\n",
    "x=''\n",
    "duplicatefields.append ('\\n\\n#####\\n\\nFields with duplicate field names \\n') \n",
    "missedfields.append ('\\n\\n######\\n\\nFields which are expected, but not in our data\\n')\n",
    "matchingfields.append ('\\n\\n#####\\n\\nFields that matched as expected') \n",
    "morethanninety.append ('\\n\\n#####\\n\\nFields without 100% match but had more than 90% Match\\n') \n",
    "lessthanninety.append ('\\n\\n#####\\n\\nFields without 100% match but had less than 90% Match\\n') \n",
    "newfields.append ('\\n\\n#####\\n\\nNew Fields , these are not found in crosswalk\\n') \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in osufields:\n",
    "    if i == 'Date': \n",
    "        x = osufields.index(i)\n",
    "        osufields[x] = osufields[x-1] +(\" \") +osufields[x]\n",
    "        continue \n",
    "for j in labfields:\n",
    "    if j == 'Date':\n",
    "        x = labfields.index(j)\n",
    "        labfields[x] = labfields[x-1] +(\" \") + labfields[x]\n",
    "df.columns = osufields\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(osufields)>len(labfields):\n",
    "    matchingfields.append('This '+filename+' file has new columns, is a high level threat, look into it.\\n')\n",
    "\n",
    "if len(osufields)<len(labfields):\n",
    "    matchingfields.append('This '+filename+' file has lesser columns than expected, is a high level threat, look into it.\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in osufields:   \n",
    "    for j in labfields:\n",
    "        if j != 'Date' and i != 'Date' :\n",
    "            if 'Date' not in i:\n",
    "                if j in i:                \n",
    "                    ratio = SequenceMatcher(None,i,j).ratio()\n",
    "                    if ratio != 1:\n",
    "\n",
    "                        duplicatefields.append(\"Warning: \"+i+ \" is a duplicate field, almost matched with \"+i +\" look into it\\n\")                    \n",
    "\n",
    "                        x = list(df.columns).index(i)\n",
    "                        cols = [i for i in range(df.shape[1])]\n",
    "                        cols.remove(x)\n",
    "                        cols.remove(x+1)\n",
    "                        df = df.iloc[:,cols]\n",
    "                        \n",
    "                        z = x+1\n",
    "                        del osufields[x]\n",
    "                        del osufields[x]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in osufields:\n",
    "    if i not in labfields:\n",
    "        newfields.append(\"Warning: \"+i+\" is a new field, look into it\\n\")        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "9FfHk22dqPzW"
   },
   "outputs": [],
   "source": [
    "\n",
    "for i in osufields:     \n",
    "    if i in labfields:\n",
    "        matchingfields.append(\"coloumn: \"+ i +\"  has sucessfully matched \\n\")\n",
    "        x = osufields.index(i)\n",
    "        y = labfields.index(i)        \n",
    "        osufields[x] = expectedfields[y]\n",
    "        continue      \n",
    "\n",
    "    else:\n",
    "        result = \"\"\n",
    "        count = 0\n",
    "        ratio = 0  \n",
    "        \n",
    "        for words in labfields:\n",
    "            ratio = SequenceMatcher(None,i,words).ratio()\n",
    "            if ratio > count:\n",
    "                count = ratio\n",
    "                result =words         \n",
    "\n",
    "        if count > 0.9:\n",
    "            x = osufields.index(i)\n",
    "            y = labfields.index(result)        \n",
    "            morethanninety.append(\"Warning: \"+osufields[x]+\" was crosswalk to \"+ result + \" has matched with more than 90% accuracy and may have an error, look into it \\n\")\n",
    "            osufields[x] = expectedfields[y]\n",
    "\n",
    "\n",
    "        elif count> 0.8:\n",
    "            x = osufields.index(i)\n",
    "            y = labfields.index(result)\n",
    "            lessthanninety.append(\"Warning: \"+osufields[x]+\" was crosswalk to \"+ result + \" has matched with more than 90% accuracy and may have an error, look into it \\n\")\n",
    "            osufields[x] = expectedfields[y]\n",
    "\n",
    "            \n",
    "            \n",
    "# temp to check the missing columns in our processed lab deliverable \n",
    "missedfields = []\n",
    "missedfields.append ('\\n\\n######\\n\\nFields which are expected, but not in our data\\n')\n",
    "temp =  expectedfields.copy()\n",
    "for i in osufields:\n",
    "    if i in temp:\n",
    "        temp.remove(i) \n",
    "for i in temp:\n",
    "    missedfields.append(\"column: \"+ i + \" is expected but is not in our current data \\n \")        \n",
    "worked_files = firstline + matchingfields + morethanninety +lessthanninety + duplicatefields + missedfields+newfields\n",
    "for i in range(len(worked_files)):\n",
    "    f.write(worked_files[i])\n",
    "        \n",
    "f.write('\\n\\n######\\nthis is end of script')\n",
    "f.close()\n",
    "df.columns = osufields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.set_option(\"display.max_rows\", None, \"display.max_columns\", None)\n",
    "# df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "-F-ZH6Qrb07l"
   },
   "outputs": [],
   "source": [
    "#saving our new csv file into a downloadable format. and it can be saved\n",
    "# df.to_csv( \"data_fieldsprocessed\"+timestr+\".csv\", index=False, encoding='utf-8-sig')\n",
    "#if you want an excel output\n",
    "# f = open\n",
    "# df.to_excel(\"pre-processed\"+timestr+\".xls\", index=False, encoding='utf-8-sig')\n",
    "# runtime for file\n",
    "runtimenow = timestr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "XE1WHQrTHT__",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'D:\\\\ROMN\\\\working\\\\Misc\\\\4People\\\\4Bala\\\\WaterQualityProcessing\\\\CCAL\\\\2020\\\\GRKO_032620_changed_names.xlsx'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# to make a duplicate of our file and export our processed \n",
    "# copyfile ('D:\\Bala\\OSU CCAL\\input\\GRKO_032620.xlsx' , './processed'+filename+'.xlsx')\n",
    "processed_path = (currentoutputpath+'\\processed'+filename)\n",
    "copyfile (data , processed_path)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename our copied file and place it at the location we want\n",
    "\n",
    "# os.rename(r'D:\\Bala\\OSU CCAL\\output\\processed.xlsx', r'D:\\Bala\\OSU CCAL\\output\\OSUCCAL_processed_' + filename + '.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "onMm_WteE2o2"
   },
   "outputs": [],
   "source": [
    "# enter the path of the processed named copy of the original file\n",
    "# processed_path = 'D:\\Bala\\OSU CCAL\\output\\OSUCCAL_processed__filename.xlsx'\n",
    "# to load our data frame into excel sheet\n",
    "book = load_workbook(processed_path)\n",
    "writer = pd.ExcelWriter(processed_path, engine = 'openpyxl')\n",
    "writer.book = book\n",
    "# enter the desired sheet name below\n",
    "sheetname = 'enter here ' + 'preprocessed' #enter your sheet name here in the space, we can have it as a prefix as you want\n",
    "df.to_excel(writer, sheet_name = sheetname)\n",
    "writer.save()\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "C0D8_3fR3swR"
   },
   "outputs": [],
   "source": [
    "# val = input(\"Do you want to merge the processed sheets into a single sheet,Enter 1 for yes, 0 for no: \") \n",
    "\n",
    "# listofdataframes = []\n",
    "# path = input(\"enter the path of folder having file\")\n",
    "# all_files = glob.glob(os.path.join(path, \"GRKO*.xlsx\"))\n",
    "# for  no,f in enumerate(all_files):\n",
    "#   df = pd.read_excel(f, sheet_name = 2)\n",
    "#   listofdataframes.append(df)\n",
    "# combined_file = pd.concat( listofdataframes) \n",
    "# timestr = time.strftime(\"_%m_%d_%Y_%H_%M\") \n",
    "# combined_file.to_csv( \"combined_csv\"+timestr+\".csv\", index=False, encoding='utf-8-sig')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "OSU CCAL",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
